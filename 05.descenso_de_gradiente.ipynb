{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descenso del gradiente\n",
    "**El objetivo del descenso del gradiente es ajustar los parámetros de un modelo de manera iterativa y gradual**, **siguiendo la dirección opuesta del gradiente** de la función objetivo, con el fin de minimizar el valor de la función.\n",
    "\n",
    "El proceso del descenso del gradiente se puede describir en los siguientes pasos:\n",
    "\n",
    "- `Inicialización de parámetros:` Se inicializan los parámetros del modelo con valores aleatorios o predefinidos.\n",
    "\n",
    "- `Cálculo del gradiente:` Se calcula el gradiente de la función objetivo con respecto a los parámetros actuales. <strong>El gradiente es un vector que indica la dirección de máximo crecimiento de la función en ese punto</strong>.\n",
    "\n",
    "- `Actualización de parámetros:` <strong>Se actualizan los parámetros del modelo en la dirección opuesta al gradiente</strong>, multiplicando el gradiente <strong>por una tasa de aprendizaje (learning rate)</strong>. La tasa de aprendizaje controla el tamaño de los pasos que se dan en cada iteración.\n",
    "\n",
    "- `Repetición:` Se repiten los pasos 2 y 3 hasta que se alcance un criterio de parada, como un número máximo de iteraciones o cuando el cambio en el valor de la función objetivo es lo suficientemente pequeño.\n",
    "\n",
    "La idea central del descenso del gradiente es que, al seguir la dirección opuesta del gradiente, se puede avanzar hacia el mínimo de la función. \n",
    "\n",
    "## Derivada \n",
    "https://www.desmos.com/calculator/l0puzw0zvm?lang=es    \n",
    "\n",
    "## Ejemplo del Descenso del gradiente\n",
    "http://www.benfrederickson.com/numerical-optimization/\n",
    "\n",
    "## Learning Rate\n",
    "<strong>El learning rate determina el tamaño de los pasos que el algoritmo toma en la dirección opuesta al gradiente</strong> para minimizar la función de pérdida durante el proceso de entrenamiento. \n",
    "\n",
    "El gradiente representa la dirección y la magnitud del cambio más rápido de la función de pérdida con respecto a los parámetros del modelo."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
